Overview of Container Orchestration
Different between Docker swarm and Kubernetes Cluster
Kubernetes Architecture
Installation of Kubernetes â€“ Minikube/Kubeadm
Kubernetes Nodes
Kubernetes Pods
Kubernetes Deployments
Rolling updates and rollbacks
Scaling up and down of the application
Services in Kubernetes
Kubernetes HostPath Volume
Namespaces

		
		
		
######################
Day 23: 12th Jan. 2026
######################
		
	Application Build and Deployment		# Based on Non-Containerized Workloads 
	
		-> Build, Create Artifacts, Deploy the Artifacts to Target.
		
	Micro-Service Based Application 		# Based on Containerized Workloads 
	
		- Application Build, Application Image Build, & Deploy the Application Services as Containers 
		
		
	- Kubernetes ::::
	
	- Docker Swarm ::::
	
		- Docker Swarm is one the Container Orchestration Tools.
		- It is meant only for Docker Containers.
		- Used to Ensure High Availability of Containers by creating Replicas of Containers.
		
		- We cannot do Auto-Scaling or Load Balancing!			
	
	
	- Kubernetes :::
		
			- It is an Open-Source Container Orchestration Tool 
			- Kubernetes is used to Deploy any type of Containers.
			- It is used to ensure high availability of the Applications/services running thru Containers.
			- Used to Ensure High Availability of Containers by creating Replicas of Containers.
			- It supports Auto-Scaling & Load Balancing.	
			- Supports self-healing.	
			
			
	- Kubernetes Architecture ::::


	CD - Pipeline: 
		
		Deploy to Kubernetes
			qa
			uat
			prod

		
		- Kubernetes_Master (VM)			==> Schedule the Deployments
		
			- Kubernetes_WorkNode1,2,3,4,5(Target Servers for deployment) 
	
	
	
	- Kubernetes Architecture Components ::::


		- Kubernetes Architecture components :::
		
			API_Server 				--> # Acts as an interface to the kubernetes 
			
			ETCD 					--> # Single point of Source for Kubernetes Components 
			
			Scheduler				--> # To identify the Healthy Node for Deployments
			
			Controller Manager 		--> # To run the pods in its desired state 
			
			
			Kubelet 				--> # Is a Kubernetes Agent used to Create & Deploy the Pods
			
			KubeProxy				--> # Is used to enable pod networking by create Pod IP Address			
			
			CRI - Container RunTime Interface (Container-D)
									--> # It is used identify the Image from Container Registry for deployment			


									
	- Kubernetes Terminologies/Concepts :::
	
		- Kubernetes Cluster 			# It is a collection of WorkNodes.
	
			Eg.:
			
				Kubernetes_Master (VM) 			# To Schedule the Pods for Deployment 
				
					Kubernetes_WorkNodes(VM) 	# To run the Application Pods 
			
			Scenario1:
			
				Kubernetes_Master (VM)
				
					Kubernetes_Cluster :							AWS Mumbai Region
						Kubernetes_WorkNode1 (VM)
						Kubernetes_WorkNode2 (VM)
						Kubernetes_WorkNode3 (VM)
						Kubernetes_WorkNode4 (VM)
						Kubernetes_WorkNode5 (VM)

			Scenario2:
			
				Kubernetes_Master (VM)
				
					Kubernetes_Cluster1 :							AWS Mumbai Region
						Kubernetes_WorkNode1 (VM)
						Kubernetes_WorkNode2 (VM)
						Kubernetes_WorkNode3 (VM)
						Kubernetes_WorkNode4 (VM)
						Kubernetes_WorkNode5 (VM)
						
					Kubernetes_Cluster2 :							AWS SNG
						Kubernetes_WorkNode1 (VM)
						Kubernetes_WorkNode2 (VM)
						Kubernetes_WorkNode3 (VM)
						Kubernetes_WorkNode4 (VM)
						Kubernetes_WorkNode5 (VM)
						
			Scenario3:
			
				Kubernetes_Master (VM)									On-Prem
				
					Kubernetes_Master1 (VM)								AWS 
						Kubernetes_Cluster1 :							AWS Mumbai Region
							Kubernetes_WorkNode1 (VM)
							Kubernetes_WorkNode2 (VM)
							Kubernetes_WorkNode3 (VM)
							Kubernetes_WorkNode4 (VM)
							Kubernetes_WorkNode5 (VM)
							
						Kubernetes_Cluster2 :							AWS SNG
							Kubernetes_WorkNode1 (VM)
							Kubernetes_WorkNode2 (VM)
							Kubernetes_WorkNode3 (VM)
							Kubernetes_WorkNode4 (VM)
							Kubernetes_WorkNode5 (VM)
						
					Kubernetes_Master2 (VM)								AZURE
						Kubernetes_Cluster1 :							AZURE Mumbai Region
							Kubernetes_WorkNode1 (VM)
							Kubernetes_WorkNode2 (VM)
							Kubernetes_WorkNode3 (VM)
							Kubernetes_WorkNode4 (VM)
							Kubernetes_WorkNode5 (VM)
							
						Kubernetes_Cluster2 :							AZURE SNG
							Kubernetes_WorkNode1 (VM)
							Kubernetes_WorkNode2 (VM)
							Kubernetes_WorkNode3 (VM)
							Kubernetes_WorkNode4 (VM)
							Kubernetes_WorkNode5 (VM)
						
						
		- Kubernetes Pods 		# 	It is an Atomic unit of schedule
		
		- Container Images 		# 	It is a static file, defines the properties and depedencies of the Application/Container.
									It is Non-Executable
									It composed of various layer of Instructions created using Dockerfile.
									
		- Containers 			# 	Executable entity of the Container-Image

		- Container Registry	# 	It is used to Store and Manage the versions of Container-Images 
									Eg.: DockerHub 
									https://hub.docker.com/
									
		- Container Repository	#	It is a subset of Container Registry
		
		- Kubectl				# 	Is a command line utility to interact with Kubernetes Master  
		
		- Kubelet 				#	Kubernetes Agent used to Deploy the Pods 	
		
		- Kubeadm 				# 	Is a command line utility to Setup the Kubernetes Architecture
		

Concepts :::
		
	- Create and Configure Kubernetes Master and WorkNodes

	- Pods & Networking
	
	- Deployment Objects 
	
		- Replicasets
		
	- Namespace
	
	- Kubernetes Services 
	
		- NodePort 
		
		- ClusterIP 
		
		- Load Balancer 
	
	- Kubernetes Volumes 
	
		- HostPath Volume 
		
		
	- Set-up Kubernetes Architecture :::

		- Managed Services 		::: EKS/AKS/GKE 
	
		- Minikube,K3s			# Single Node Light Weight Kubernetes Cluster - Used just for Learning/Practice Kubectl Commands 
								# Kubernetes_Master	(VM)
								
		- Kubeadm				# Multi-Node Kubernetes Cluster - Used in Production Implementations
								# Kubernetes_Master	(VM)
									Kubernetes_WorkerNode1 (VM)
									kubernetes_WorkerNode2 (VM)	

	
	- Set-up Open-Source Kubernetes Architecture using Kubeadm :::
	
		https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/
		
		
	- DevOps Resource :::
	
		Kubernetes :: 
		
			- Kubernetes Developer/Admin/Security_Admin
		
		- Kubernetes_Master (VM)
			- Kubernetes_WorkerNode1 (VM)
			- Kubernetes_WorkerNode2 (VM)
			
			
		Kubernetes Master and Worker Node Configurations :::

			Installation of Kubernetes using Kubeadm :::	
			
					1. Launch 3 VMs on AWS Cloud (Ubuntu v22.04) --> (1 Master Node, 2 WorkerNodes)
				
				In all the Nodes(i.e., Master Node and WorkerNodes):
				
					2. Allow all traffic for all the nodes - just for this demo
					3. Change the HostName of all the Nodes
					4. Disable swap configuration in all the nodes
					5. Install Docker in all the nodes *** (Optional)
					6. Install CRI - 'Container-D' in all the nodes
					7. Install Kubeadm,kubelet,kubectl 
					8. Enable Kubelet	
				   
				Only on Master Node:
				
					9. Execute Kubeadm Init Command 		# To initialize Kubernetes Master Node
					10. Enable user Access to Kubernetes
					11. Install flannel Network plugins for kubeproxy

				Only on WorkerNodes:		
				
					12. Execute Kubeadm Join Command 		# To attach the Worknodes with Kubernetes Master Node.



######################
Day 24: 13th Jan. 2026
######################		
		
	- Create and Configure Kubernetes Master and WorkNodes :::

	- Pods & Networking :::
		
		Kubectl Commands Options 
		
		Pods & Pod Networking 
		
		Create and Deploy Pods
		
			- Create Manifest file - *.yaml		# Define the Properties of the Kubernetes Objects to be deployed.
			
			
		
		
*******************************************************************
# 1. 	Create Pod Object Manifest File :

# nginx-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
    tier: dev
spec:
  containers:
  - name: nginx-container
    image: nginx
    ports:
    - containerPort: 80

*******************************************************************

2. Create and display Pods

# Create and display PODs

#kubectl apply -f nginx-pod.yaml

kubectl create -f nginx-pod.yaml
kubectl get pod
kubectl get pod -o wide
kubectl get pod nginx-pod -o yaml
kubectl describe pod nginx-pod

*******************************************************************

# Expose PODS using NodePort service

kubectl expose pod nginx-pod --type=NodePort --port=80

#NodePort Service Create Port between - 30000 to 32767

kubectl get svc

# Node-Port Range : 30000 - 32767 

# Display Service and find NodePort
kubectl describe svc nginx-pod

# Open Web-browser and access webapge using 
http://<external-nodeip>:<nodeport>
#eg.: http://13.203.209.177:32328



# Delete pod & svc
kubectl delete svc nginx-pod
kubectl delete pod nginx-pod


*******************************************************************

Next ::::

	
	- Deployment Objects 
	
		- Replicasets
		
	- Namespace
	
	- Kubernetes Services 
	
		- NodePort 
		
		- ClusterIP 
		
		- Load Balancer 
	
	- Kubernetes Volumes 
	
		- HostPath Volume 
			
		
######################
Day 25: 15th Jan. 2026
######################	

	- Controller Object :::
	
		ReplicaSet 
	
		Deployment 

		ReplicaSet :::
		
			--> Replicaset is used to execute the specific no. of pods in the cluster.
			--> Replicaset uses the Set Based Operator
			--> Used to replicate the pods and able to scale up/down
			--> The Replicasets will be automatically created, while creating Deployment Controller Object.
		
		
		Deployment Controller Object :::
		
			--> It is used to deploy the pods and ensure high availability of pods by creating pod replicas 
			--> 1. Create Muliple instance/replicas/copies of pods 
				2. Used to Scale-Up / Scale-Down the Pods 
				3. Used to Upgrade the application pods 
				4. Used to Down-grade/roll-back the application pods
			--> The upgrade/down-grade of application pods can be done without any downtime. 
			--> To achieve zero-downtime during upgrade/down-grade, By Default, it used Rolling-Update Deployment Strategy.
				- Supports self-healing.		
			
			
			web_app_image:v1.0		==> 	web_app_image:v1.1
			
			pod_1.1:v1.0			==>		pod_1.1:v1.1	
			pod_1.2:v1.0			==>		pod_1.2:v1.1
			pod_1.3:v1.0			==>		pod_1.2:v1.0
				
				
		Create Manifest file to work with Deployment Controller Object ::::		
		
		Deployment Controller Object creates :
		
			- Deployment 
			- Replicaset
			- Pod Instances 		
		
			
	- Kubernetes Namespace ::::	

		- Logical Partitioning of Kubernetes Cluster.
		
		- Namespaces are created based on the Envionments/Teams/Deployment Strategies.	
		
		
		Environments :::
		
			Dev VM 
			
			QA  VM
			
			UAT VM 
			
			PROD VM1,2,3,4,5
			
			
		Kubernetes_Master				(Non-Prod)
		
			Kubernetes_WorkerNode1,2,3,4,5,6,7,8,9,10
			
			
		Kubernetes_Master				(Prod)
		
			Kubernetes_WorkerNode1,2,3,4,5,6,7,8,9,10
			
			
		kubectl get ns 
		
		kubectl create namespace dev 
			
		kubectl create namespace qa

		kubectl create namespace uat

root@kmaster-node:~/kubernetes# vi nginx-pod.yaml

apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  namespace: dev
  labels:
	app: nginx
	tier: dev
spec:
  containers:
  - name: nginx-container
	image: nginx
	ports:
	- containerPort: 80
			
		kubectl create -f nginx-pod.yaml 
		
		kubectl get pods -n dev	
		
		kubectl get pods -n kube-system
			
			

Windows :

C: 


D:
	Proj_Folder_Dev 	--> Logical ==> Namespace!
	 file1 							==> Pods 
	Proj_Folder_QA 		--> Logical 
	 file1 	 
	 
		
		
- Kubernetes Volumes 
	
	- Used to maintain the Persistant Data!

	- HostPath Volume:
	
		- It same as like Docker Volume.
		- It is applicable at the Pod Level. 
		- HostPath Volumes are created on the Host Machine, where the pod get deployed at runtime.
		- Pods can use this Hostpath Volume to maintain the Input and out Files.
		
	
Next ::

	- Create HostPath Volume 
	- Attach it to the Pods.

	- Kubernetes Services 
	
		- NodePort 		
		- ClusterIP		
		- Load Balancer 		
		
	- Implement CICD Pipeline using Kubernetes.



######################
Day 26: 16th Jan. 2026
######################	
		
- Kubernetes Volumes 
	
	- Used to maintain the Persistant Data!

	- HostPath Volume:
	
		- It same as like Docker Volume.
		- It is applicable at the Pod Level. 
		- HostPath Volumes are created on the Host Machine, where the pod get deployed at runtime.
		- Pods can use this Hostpath Volume to maintain the Input and out Files.
		
	- Create HostPath Volume 	
	
	- Attach it to the Pods.
	
	
	- Persistant Volume				# Is used to allocate the Persistant Volumes to the Pods from the external Storage Medium
									# Used to reserve huge amount of data at the cluster level 
									# It abstracts the Volume allocation process.
	
	- Persistant Volume Claim		# Developers create the Persistant Volume Claim (Request Form)
									# Storage Administrators process the Claim and allocate the requested volume using Persistant Volume Pool.
									# Persistant Volume Claim is attached to the Pods 
	
	
		- Kubernetes_Master (VM)
			- Kubernetes_WorkerNode1 (VM)
			- Kubernetes_WorkerNode2 (VM)	
			
			
	- Kubernetes Services 

	- NodePort 				# To Expose the pods to internet
							# It is applicable at the application service level
							# It assigns the ports- 30000 to 32767
							
	- ClusterIP				# To enable the pod communication within the cluster
	
	- Load Balancer			# To access the application usind external Load Balancer services.
							# Route the traffic to a pod instance 
							# Listener Rules: ALB,NLB,GLB
							# Load Balancer is created at the Application Level
							
							
		- Using Load Balancer, how the request are routed? 
		
		Types of Routing:
		
			- Simple Routing 				# Meant for a Static web page using complete <URL>
			
			- Host Based Routing 			# Meant for a Dynamic web sites
			
			- Path Based Routing 			# Meant for a Dynamic web sites
			
			- Query Based Routing			# Meant for a Dynamic web sites
			
			
			
			
			www.google.com 					# Web Application
			
			
			gmail 				-> www.google.mail.com					# Host Based Routing 
			
			maps 				-> www.google.maps.com
			
			translate			-> www.google.translate.com 
			
			drive 				-> www.google.drive.com
			
			
			
			www.google.mail.com	
			
			
			inbox 				- www.google.mail.com/inbox				# Path Based Routing 
			
			sent 				- www.google.mail.com/sent
			
			trash 				- www.google.mail.com/trash
			
			
			
			inbox 				- www.google.mail.com/inbox?email=Hello  #Query Based Routing

		
		
	- Implement CICD Pipeline using Kubernetes.
	
		- Integrate Kubernetes & Jenkins 
		
		

Existing Jenkins Pipeline :::

Stages:

	CI - Pipeline: 

		1. SCM_Checkout
		2. Application_Build								=> *.war
		3. Application_Image_Build							=> appln_img:v1.0
		4. Login to DockerHub 
		5. Push the appbuild_img1:v1.0 to DockerHub 

Enhance this using Kubernetes :
	
Enhanced CI/CD Pipeline :
 
	1. SCM_Checkout
	2. Application_Build								=> *.war
	3. Application_Image_Build							=> appln_img:v1.0
	4. Login to DockerHub 
	5. Push the appbuild_img1:v1.0 to DockerHub 
	6. Deploy to Kubernetes


Implementation of CI Pipeline:

	- Jenkins_Master 							==>		Install git,jdk,jenkins 	
		- Jenkins_SlaveNode1(Build_Server)		==>		Install git,jdk,maven,docker
		
	- Kubernetes_Master (VM)
		- Kubernetes_WorkerNode1 (VM)
		- Kubernetes_WorkerNode2 (VM)

	Pre-requisites :::
	
		- Goto Jenkins Credential Manager and Create the DockerHub Credentials to use in the Pipeline.
		
		- Used the Credentials as Environment Variables within the pipeline script.
		
		- As a root user run this command on Slave_Node: 
			
			usermod -aG docker devopsadmin
		
		- reboot slave_node
		
		
		- Intergrate Kubernetes Master to Jenkins Master :::

			Use SSH Connection between Jenkins and Kubernetes Master
			
				Create a user in Kubernetes Master 
				Grant Access to Kubectl
				
				Use Publish Over SSH Plugins to connect Kubernetes		
			
		- Update Manifest file in Github Repository to create the Kubernetes Deployment and NodePort Service Objects

	
# kdeploy.yaml		

apiVersion: apps/v1
kind: Deployment
metadata:
  name: loksai-eta-deploy
  labels:
    app: loksai-eta-deploy-lbl
spec:
  replicas: 3
  selector:
    matchLabels:
      app: loksai-eta-app
  template:
    metadata:
      labels:
        app: loksai-eta-app
    spec:
      containers:
      - name: loksai-eta-container
        image: loksaieta/plwebappimg:v1.0
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: loksai-eta-np-service
  labels:
    app: loksai-eta-app
spec:
  selector:
    app: loksai-eta-deploy-lbl

  type: NodePort
  ports:
  - nodePort: 31028
    port: 8080
    targetPort: 8080


		
pipeline {

    agent { label 'slave1' }

	environment {	
		DOCKERHUB_CREDENTIALS=credentials('dockerloginid')
	}	
	
    stages {
        stage('SCM_Checkout') {
            steps {
                echo 'Perform SCM Checkout'	
				git 'https://github.com/PL-DevOps-GenAI-A1125/java-webapp-project.git'
				
            }
        }
        stage('Application_Build') {
            steps {
                echo 'Perform Maven Application Build'
				sh 'mvn clean package'				
            }
        }
        stage('Application_Image_Build') {
            steps {
                echo 'Perform Docker Application Image Build'
				sh "docker build -t loksaieta/plwebappimg:v1.0 ."			
            }
        }
        stage('Login to DockerHub') {
            steps {
                echo 'Login to Container Registry'
				sh 'echo $DOCKERHUB_CREDENTIALS_PSW | docker login -u $DOCKERHUB_CREDENTIALS_USR --password-stdin'
            }
        }
        stage('Publish Application_Image to DockerHub') {
            steps {
                echo 'Publish Application_Image to DockerHub'
				sh "docker push loksaieta/plwebappimg:v1.0"	
            }
        }
        stage('Deploy to Kubernetes') {
            steps {
				script 
				{
				sshPublisher(publishers: [sshPublisherDesc(configName: 'Kubernetes_Master', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: 'kubectl apply -f kubedeploy.yaml', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '.', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '*.yaml')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)])
				}
			}
        }
    }
}
